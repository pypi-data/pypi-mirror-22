{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DLTK imports  \n",
    "import dltk.core.modules as modules\n",
    "from dltk.models.segmentation.unet import ResUNET\n",
    "\n",
    "import mrbrains_reader as reader\n",
    "\n",
    "# Set the CUDA_VISIBLE_DEVICES environmental variable to GPU ids to compute on\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "# Save path for log files and model parameters\n",
    "save_path =  '/tmp/MRBrainS13'\n",
    "os.system(\"rm -rf \" + save_path)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get a list of paths to the training images, interpretable by the custom MRBrainS13 file reader\n",
    "def train_files():\n",
    "    return [[\"../../data/MRBrainS13DataNii/TrainingData/1/\",\n",
    "            \"../../data/MRBrainS13DataNii/TrainingData/2/\",\n",
    "            \"../../data/MRBrainS13DataNii/TrainingData/3/\",\n",
    "            \"../../data/MRBrainS13DataNii/TrainingData/4/\",\n",
    "            \"../../data/MRBrainS13DataNii/TrainingData/5/\"]]\n",
    "\n",
    "                 # Set up a batcher op to spawn a custom reader and produce pairs of training images and\n",
    "# labels (X_train and Y_train, respectively). These pairs are 5D tf.Tensors with the dimensions\n",
    "# [batch_size, x, y, z, num_channels]. Our reader will produce axial slice training examples of shape\n",
    "# [4, 1, 256, 256, 3]\n",
    "num_classes = 9\n",
    "num_channels = 3\n",
    "batch_size = 4\n",
    "\n",
    "# I/O ops for training and validation via a custom mrbrains_reader\n",
    "x_train, y_train = reader.MRBrainsReader([tf.float32, tf.int32], [[24, 64, 64, 3], [24, 64, 64]], name='train_queue')(\n",
    "    train_files(), batch_size=batch_size, n_examples=18, min_queue_examples=batch_size * 2, capacity=batch_size * 4)    \n",
    "\n",
    "# Create a segmentation network. Here we use a U-NET [1] architecture with residual feature encoder [2].\n",
    "# Strided convolutions are employed for downsampling, resulting in 3 feature scales, each with two \n",
    "# residual units.\n",
    "# [1] O.Ronneberger et al. (2015). U-net: Convolutional networks for biomedical image segmentation. MICCAI.\n",
    "# [2] K.He et al (2016). Deep residual learning for image recognition. IEEE CVPR.\n",
    "net = ResUNET(num_classes, \n",
    "              num_residual_units=2,\n",
    "              filters=[16, 32, 64],\n",
    "              strides=[[1,1,1], [1,2,2], [1,2,2]])\n",
    "\n",
    "# For training, we compute the mean categorical crossentropy as a loss function\n",
    "train_logits_ = net(x_train)['logits']\n",
    "train_truth_ = y_train\n",
    "crossentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=train_logits_, labels=train_truth_)\n",
    "train_loss_ = tf.reduce_mean(crossentropy, name='crossentropy')\n",
    "\n",
    "# Set up an optimiser\n",
    "train_op_ = tf.train.MomentumOptimizer(0.001, 0.9).minimize(train_loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional ops to visualise the segmentation output\n",
    "out_y_ = net(x_train, is_training=False)['y_']\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up a supervisor to continuously save and log the training progress, handle queues and initialise variables \n",
    "step = 0\n",
    "loss_moving = []  \n",
    "sv = tf.train.Supervisor(logdir=save_path,\n",
    "                         is_chief=True,\n",
    "                         summary_op=None,\n",
    "                         save_summaries_secs=30,\n",
    "                         save_model_secs=60,\n",
    "                         global_step=global_step)\n",
    "\n",
    "s = sv.prepare_or_wait_for_session(config=tf.ConfigProto())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training loop  \n",
    "while not sv.should_stop():\n",
    "\n",
    "    # Run the training op and log the ce loss\n",
    "    _, loss = s.run([train_op_, train_loss_])\n",
    "    loss_moving.append(loss)    \n",
    "\n",
    "    # Run a forward pass and return prediction (y_), input image (x) and corresponding truth (y)\n",
    "    y_, x, y = s.run([out_y_, x_train, y_train])\n",
    "    \n",
    "    # Visualise all inputs, outputs and losses during each training step\n",
    "    if True:\n",
    "        f, axarr = plt.subplots(2, 3, figsize=(16,8))\n",
    "        axarr[0,0].imshow(np.squeeze(x[0,0,:,:,0]), cmap='gray')\n",
    "        axarr[0,0].set_title('Input T1: x')\n",
    "        axarr[0,0].axis('off')\n",
    "\n",
    "        axarr[0,1].imshow(np.squeeze(x[0,0,:,:,1]), cmap='gray')\n",
    "        axarr[0,1].set_title('Input T1 IR: x')\n",
    "        axarr[0,1].axis('off')\n",
    "\n",
    "        axarr[0,2].imshow(np.squeeze(x[0,0,:,:,2]), cmap='gray')\n",
    "        axarr[0,2].set_title('Input T2 FLAIR: x')\n",
    "        axarr[0,2].axis('off')\n",
    "\n",
    "        axarr[1,0].plot(loss_moving)\n",
    "        axarr[1,0].set_title('Crossentropy loss')\n",
    "        axarr[1,0].axis('on')\n",
    "\n",
    "        axarr[1,1].imshow(np.squeeze(y_[0,0,:,:]), cmap='jet', vmin=0, vmax=num_classes)\n",
    "        axarr[1,1].set_title('Prediction: y_')\n",
    "        axarr[1,1].axis('off')\n",
    "\n",
    "        axarr[1,2].imshow(np.squeeze(y[0,0,:,:]), cmap='jet', vmin=0, vmax=num_classes)\n",
    "        axarr[1,2].set_title('Truth: y')\n",
    "        axarr[1,2].axis('off')\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        plt.close(f)\n",
    "\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
