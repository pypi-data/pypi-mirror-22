import csv

configfile: config["cfp"]

allsamples = config["allsamples"]
scriptdir = config["scriptdir"]
outdir = config["outdir"]
PEAT = config["PEAT"]
pigz = config["pigz"]

trimdir = outdir + "/01_trimmed"

# Create dictionary of reads indexed by sample IDs
with open(allsamples, mode='r') as infile:
    reader = csv.reader(infile)
    mydict = {rows[0]:{'a': rows[1], 'b':rows[2].strip()} for rows in reader}

Samples = list(mydict.keys())

rule all:
    input:
        expand(trimdir + '_reads/{sample}_paired1.fq.gz', sample=Samples),
        expand(trimdir + '_reads/{sample}_paired2.fq.gz', sample=Samples)

rule trim: 
	input: 
		a = lambda wildcards: mydict[wildcards.sample]['a'],
		b = lambda wildcards: mydict[wildcards.sample]['b']
	output:
		trimdir + '_reads/{sample}_paired1.fq',
		trimdir + '_reads/{sample}_paired2.fq'
	threads: 2
	shell:
		PEAT + " paired -1 {input.a} -2 {input.b} -o " + trimdir + "_reads/{wildcards.sample} -n {threads} -l 20 -r 0.1 -a 0.1 -g 0.1 --adapter_contexts"

rule compress:
	input:
		u1 = trimdir + '_reads/{sample}_paired1.fq',
		u2 = trimdir + '_reads/{sample}_paired2.fq',
	output:
		trimdir + '_reads/{sample}_paired1.fq.gz',
		trimdir + '_reads/{sample}_paired2.fq.gz',
	threads: 4
	shell:
		pigz + " -p {threads} {input.u1} && " + pigz + " -p {threads} {input.u2}"
		