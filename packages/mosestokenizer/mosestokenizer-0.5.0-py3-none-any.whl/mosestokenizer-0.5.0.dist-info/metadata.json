{"classifiers": ["Development Status :: 4 - Beta", "Intended Audience :: Developers", "Topic :: Text Processing :: Linguistic", "License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)", "Programming Language :: Python :: 3.5"], "extensions": {"python.commands": {"wrap_console": {"moses-detokenizer": "mosestokenizer.detokenizer:main", "moses-punct-normalizer": "mosestokenizer.punctnormalizer:main", "moses-sent-splitter": "mosestokenizer.sentsplitter:main", "moses-tokenizer": "mosestokenizer.tokenizer:main"}}, "python.details": {"contacts": [{"email": "luismsgomes@gmail.com", "name": "Lu\u00eds Gomes", "role": "author"}], "document_names": {"description": "DESCRIPTION.rst"}, "project_urls": {"Home": "https://bitbucket.org/luismsgomes/mosestokenizer"}}, "python.exports": {"console_scripts": {"moses-detokenizer": "mosestokenizer.detokenizer:main", "moses-punct-normalizer": "mosestokenizer.punctnormalizer:main", "moses-sent-splitter": "mosestokenizer.sentsplitter:main", "moses-tokenizer": "mosestokenizer.tokenizer:main"}}}, "extras": [], "generator": "bdist_wheel (0.29.0)", "keywords": ["text", "tokenization", "pre-processing"], "license": "LGPLv2", "metadata_version": "2.0", "name": "mosestokenizer", "run_requires": [{"requires": ["docopt", "openfile", "toolwrapper"]}], "summary": "Wrappers for several pre-processing scripts from the Moses toolkit.", "version": "0.5.0"}