@incollection{AdobeSystems2012,
abstract = {This publication and the information herein is furnished AS IS, is subject to change without notice, and should not be construed as a commitment by Adobe Systems Incorporated. Adobe Systems Incorporated assumes no responsibility or liability for any errors or inaccuracies, makes no warranty of any kind (express, implied, or statutory) with respect to this publication, and expressly disclaims any and all warranties of merchantability, fitness for particular purposes, and noninfringement of third party rights.},
author = {{Adobe Systems}},
booktitle = {Digital Negative (DNG) Specification},
pages = {81},
title = {{Camera to XYZ (D50) Transform}},
year = {2012}
}
@book{Banterle2011d,
author = {Banterle, Francesco and Artusi, Alessandro and Debattista, Kurt and Chalmers, Alan},
booktitle = {Advanced High Dynamic Range Imaging},
isbn = {978-1568817194},
pages = {12--17},
publisher = {A K Peters/CRC Press},
title = {{2.1.1 Generating HDR Content by Combining Multiple Exposures}},
year = {2011}
}
@misc{McGuffog2012,
author = {McGuffog, Sandy},
title = {{Hue Twists in DNG Camera Profiles}},
url = {http://dcptool.sourceforge.net/Hue Twists.html},
urldate = {2016-10-29},
year = {2012}
}
@misc{Lagarde2016,
author = {Lagarde, Sebastien and Lachambre, Sebastien and Jover, Cyril},
file = {:Users/kelsolaar/Documents/Mendeley Desktop/Lagarde, Lachambre, Jover - 2016 - An Artist-Friendly Workflow for Panoramic HDRI.pdf:pdf},
title = {{An Artist-Friendly Workflow for Panoramic HDRI}},
url = {http://blog.selfshadow.com/publications/s2016-shading-course/unity/s2016{\_}pbs{\_}unity{\_}hdri{\_}notes.pdf},
year = {2016}
}
@misc{AdobeSystems2015a,
author = {{Adobe Systems}},
title = {{Adobe DNG SDK 1.4}},
url = {http://download.adobe.com/pub/adobe/dng/dng{\_}sdk{\_}1{\_}4.zip},
year = {2015}
}
@incollection{AdobeSystems2012,
abstract = {This publication and the information herein is furnished AS IS, is subject to change without notice, and should not be construed as a commitment by Adobe Systems Incorporated. Adobe Systems Incorporated assumes no responsibility or liability for any errors or inaccuracies, makes no warranty of any kind (express, implied, or statutory) with respect to this publication, and expressly disclaims any and all warranties of merchantability, fitness for particular purposes, and noninfringement of third party rights.},
author = {{Adobe Systems}},
booktitle = {Digital Negative (DNG) Specification},
pages = {80--81},
title = {{Translating Camera Neutral Coordinates to White Balance xy Coordinates}},
year = {2012}
}
@misc{Tumblin1999,
abstract = {High contrast images are common in night scenes and other scenes that include dark shadows and bright light sources. These scenes are difficult to display because their contrasts greatly exceed the range of most display devices for images. As a result, the image constrasts are compressed or truncated, obscuring subtle textures and details. Humans view and understand high contrast scenes easily, “adapting” their visual response to avoid compression or truncation with no apparent loss of detail. By imitating some of these visual adaptation processes, we developed methods for the improved display of high-contrast images. The first builds a display image from several layers of lighting and surface properties. Only the lighting layers are compressed, drastically reducing contrast while preserving much of the image detail. This method is practical only for synthetic images where the layers can be retained from the rendering process. The second method interactively adjusts the displayed image to preserve local contrasts in a small “foveal” neighborhood. Unlike the first method, this technique is usable on any image and includes a new tone reproduction operator. Both methods use a sigmoid function for contrast compression. This function has no effect when applied to small signals but compresses large signals to fit within an asymptotic limit. We demonstrate the effectiveness of these approaches by comparing processed and unprocessed images.},
author = {Tumblin, Jack and Hodgins, Jessica K. and Guenter, Brian K.},
booktitle = {ACM Transactions on Graphics},
doi = {10.1145/300776.300783},
file = {:Users/kelsolaar/Documents/Mendeley Desktop/Tumblin, Hodgins, Guenter - 1999 - Two methods for display of high contrast images.pdf:pdf},
isbn = {0730-0301},
issn = {07300301},
number = {1},
pages = {56--94},
title = {{Two methods for display of high contrast images}},
volume = {18},
year = {1999}
}
@misc{AdobeSystems2015,
author = {{Adobe Systems}},
title = {{Adobe DNG SDK 1.4 - dng{\_}sdk{\_}1{\_}4/dng{\_}sdk/source/dng{\_}camera{\_}profile.cpp - dng{\_}camera{\_}profile::IlluminantToTemperature}},
url = {http://download.adobe.com/pub/adobe/dng/dng{\_}sdk{\_}1{\_}4.zip},
year = {2015}
}
@misc{Wikipediaa,
author = {Wikipedia},
title = {{Tonemapping - Purpose and methods}},
url = {http://en.wikipedia.org/wiki/Tone{\_}mapping{\#}Purpose{\_}and{\_}methods},
urldate = {2015-03-15}
}
@book{Banterle2011a,
author = {Banterle, Francesco and Artusi, Alessandro and Debattista, Kurt and Chalmers, Alan},
booktitle = {Advanced High Dynamic Range Imaging},
isbn = {978-1568817194},
pages = {38--41},
publisher = {A K Peters/CRC Press},
title = {{3.2.1 Simple Mapping Methods}},
year = {2011}
}
@book{AdobeSystems2012a,
abstract = {This publication and the information herein is furnished AS IS, is subject to change without notice, and should not be construed as a commitment by Adobe Systems Incorporated. Adobe Systems Incorporated assumes no responsibility or liability for any errors or inaccuracies, makes no warranty of any kind (express, implied, or statutory) with respect to this publication, and expressly disclaims any and all warranties of merchantability, fitness for particular purposes, and noninfringement of third party rights.},
author = {{Adobe Systems}},
file = {:Users/kelsolaar/Documents/Mendeley Desktop/Adobe Systems - 2012 - Digital Negative (DNG) Specification.pdf:pdf},
pages = {1--101},
title = {{Digital Negative (DNG) Specification}},
year = {2012}
}
@book{Banterle2011b,
author = {Banterle, Francesco and Artusi, Alessandro and Debattista, Kurt and Chalmers, Alan},
booktitle = {Advanced High Dynamic Range Imaging},
isbn = {978-1568817194},
pages = {41--43},
publisher = {A K Peters/CRC Press},
title = {{3.2.2 Brightness Reproduction}},
year = {2011}
}
@misc{Habble2010,
author = {Habble, John},
title = {{Filmic Tonemapping Operators}},
url = {http://filmicgames.com/archives/75},
urldate = {2015-03-15},
year = {2010}
}
@misc{Banterle2014,
author = {Banterle, Francesco and Benedetti, Luca},
title = {{PICCANTE: An Open and Portable Library for HDR Imaging}},
year = {2014}
}
@book{Banterle2011c,
author = {Banterle, Francesco and Artusi, Alessandro and Debattista, Kurt and Chalmers, Alan},
booktitle = {Advanced High Dynamic Range Imaging},
isbn = {978-1568817194},
pages = {43--46},
publisher = {A K Peters/CRC Press},
title = {{3.2.3 Quantization Techniques}},
year = {2011}
}
@misc{Habble2010a,
author = {Habble, John},
title = {{Uncharted 2: HDR Lighting}},
url = {http://www.slideshare.net/ozlael/hable-john-uncharted2-hdr-lighting},
urldate = {2015-03-15},
year = {2010}
}
@book{Banterle2011,
author = {Banterle, Francesco and Artusi, Alessandro and Debattista, Kurt and Chalmers, Alan},
isbn = {978-1568817194},
pages = {352},
publisher = {A K Peters/CRC Press},
title = {{Advanced High Dynamic Range Imaging}},
year = {2011}
}
@article{Debevec1997,
abstract = {We present a method of recovering high dynamic range radiance maps from photographs taken with conventional imaging equip- ment. In our method, multiple photographs of the scene are taken with different amounts of exposure. Our algorithm uses these dif- ferently exposed photographs to recover the response function of the imaging process, up to factor of scale, using the assumption of reci- procity. With the known response function, the algorithm can fuse themultiple photographs into a single, high dynamic range radiance map whose pixel values are proportional to the true radiance values in the scene. We demonstrate our method on images acquired with both photochemical and digital imaging processes. We discuss how this work is applicable in many areas of computer graphics involv- ing digitized photographs, including image-based modeling, image compositing, and image processing. Lastly, we demonstrate a few applications of having high dynamic range radiance maps, such as synthesizing realistic motion blur and simulating the response of the human visual system.},
author = {Debevec, Paul and Malik, Jitendra},
doi = {10.1145/258734.258884},
file = {:Users/kelsolaar/Documents/Mendeley Desktop/Debevec, Malik - 1997 - Recovering High Dynamic Range Radiance Maps from Photographs.pdf:pdf},
isbn = {0897918967},
issn = {00978930},
number = {August},
pages = {1--10},
title = {{Recovering High Dynamic Range Radiance Maps from Photographs}},
year = {1997}
}
@incollection{AdobeSystems2012,
abstract = {This publication and the information herein is furnished AS IS, is subject to change without notice, and should not be construed as a commitment by Adobe Systems Incorporated. Adobe Systems Incorporated assumes no responsibility or liability for any errors or inaccuracies, makes no warranty of any kind (express, implied, or statutory) with respect to this publication, and expressly disclaims any and all warranties of merchantability, fitness for particular purposes, and noninfringement of third party rights.},
author = {{Adobe Systems}},
booktitle = {Digital Negative (DNG) Specification},
pages = {80},
title = {{Translating White Balance xy Coordinates to Camera Neutral Coordinates}},
year = {2012}
}
@misc{UnityTechnologies2016,
author = {{Unity Technologies}},
title = {{Treasure Island - white balanced.exr}},
url = {http://blog.selfshadow.com/publications/s2016-shading-course/unity/supplemental/Treasure Island - white balanced.exr},
urldate = {2016-08-30},
year = {2016}
}
@article{Grossberg2003,
abstract = { An image acquired by a camera consists of measured intensity values which are related to scene radiance by a function called the camera response function. Knowledge of this response is necessary for computer vision algorithms which depend on scene radiance. One way the response has been determined is by establishing a mapping of intensity values between images taken with different exposures. We call this mapping the intensity mapping function. In this paper, we address two basic questions. What information from a pair of images taken at different exposures is needed to determine the intensity mapping function? Given this function, can the response of the camera and the exposures of the images be determined? We completely determine the ambiguities associated with the recovery of the response and the ratios of the exposures. We show all methods that have been used to recover the response break these ambiguities by making assumptions on the exposures or on the form of the response. We also show when the ratio of exposures can be recovered directly from the intensity mapping, without recovering the response. We show that the intensity mapping between images is determined solely by the intensity histograms of the images. We describe how this allows determination of the intensity mapping between images without registration. This makes it possible to determine the intensity mapping in sequences with some motion of both the camera and objects in the scene.},
author = {Grossberg, Michael D. and Nayar, Shree K.},
doi = {10.1109/TPAMI.2003.1240119},
file = {:Users/kelsolaar/Documents/Mendeley Desktop/Grossberg, Nayar - 2003 - Determining the camera response from images What is knowable.pdf:pdf},
isbn = {0-7695-1900-8},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Ambiguities,Calibration,Comparagram,Comparametric,Dynamic range,Histogram,Histogram specification,Illumination,Intensity mapping,Radiometry,Response function},
number = {11},
pages = {1455--1467},
title = {{Determining the camera response from images: What is knowable?}},
volume = {25},
year = {2003}
}
@misc{Wikipedia,
author = {Wikipedia},
title = {{EV as a measure of luminance and illuminance}},
url = {https://en.wikipedia.org/wiki/Exposure{\_}value{\#}EV{\_}as{\_}a{\_}measure{\_}of{\_}luminance{\_}and{\_}illuminance},
urldate = {2015-11-14}
}
@article{Reinhard2005,
abstract = {A common task in computer graphics is the mapping of digital high dynamic range images to low dynamic range display devices such as monitors and printers. This task is similar to the adaptation processes which occur in the human visual system. Physiological evidence suggests that adaptation already occurs in the photoreceptors, leading to a straightforward model that can be easily adapted for tone reproduction. The result is a fast and practical algorithm for general use with intuitive user parameters that control intensity, contrast, and level of chromatic adaptation, respectively.},
author = {Reinhard, Erik and Devlin, Kate},
doi = {10.1109/TVCG.2005.9},
file = {:Users/kelsolaar/Documents/Mendeley Desktop/Reinhard, Devlin - 2005 - Dynamic range reduction inspired by photoreceptor physiology.pdf:pdf},
isbn = {1077-2626 (Print)$\backslash$r1077-2626 (Linking)},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Dynamic range reduction,Photoreceptor physiology,Tone reproduction},
number = {1},
pages = {13--24},
pmid = {15631125},
title = {{Dynamic range reduction inspired by photoreceptor physiology}},
volume = {11},
year = {2005}
}
@article{Schlick1994,
abstract = {This paper proposes several techniques that enable to display high dynamic range pictures (created by a global illumination rendering program, for instance) on a low dynamic range device. The methods described here are based on some basic knowledge about human vision and are intended to provide "realistic looking" images on the visualization device, even with critical lighting conditions in the rendered scene. The main features of the new techniques are speed (only a handful of floating point operations per pixel are needed) and simplicity (only one single parameter, which can be empirically evaluated has to be provided by the user). The goal of this paper is not to propose a psychovisual or neurological model for subjective perception, but only to described some experimental results and propose some possible research directions.},
author = {Schlick, Christophe},
file = {:Users/kelsolaar/Documents/Mendeley Desktop/Schlick - 1994 - Quantization Techniques for Visualization of High Dynamic Range Pictures.pdf:pdf},
issn = {0920-5691},
journal = {Proceedings of the Fifth Eurographics Workshop on Rendering},
keywords = {dynamic range,subjective brightness perception,tone reproduction},
number = {Section 5},
pages = {7--18},
title = {{Quantization Techniques for Visualization of High Dynamic Range Pictures}},
year = {1994}
}
@article{Viriyothai2009,
author = {Viriyothai, K and Debevec, Paul},
doi = {10.1145/1599301.1599393},
file = {:Users/kelsolaar/Documents/Mendeley Desktop/Viriyothai, Debevec - 2009 - Variance minimization light probe sampling.pdf:pdf},
isbn = {9781605587264},
journal = {SIGGRAPH'09: Posters},
number = {Egsr},
pages = {60558},
title = {{Variance minimization light probe sampling}},
url = {http://dl.acm.org/citation.cfm?id=1599393},
year = {2009}
}
@misc{AdobeSystems2015,
author = {{Adobe Systems}},
title = {{Adobe DNG SDK 1.4 - dng{\_}sdk{\_}1{\_}4/dng{\_}sdk/source/dng{\_}tag{\_}values.h - LightSource tag}},
url = {http://download.adobe.com/pub/adobe/dng/dng{\_}sdk{\_}1{\_}4.zip},
year = {2015}
}
