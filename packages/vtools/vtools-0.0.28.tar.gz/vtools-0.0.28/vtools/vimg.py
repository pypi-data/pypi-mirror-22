####################################################################################################
########################################### vtools.vimg ############################################
############################################# vimg.py ##############################################
####################################################################################################
######################################## Import Statements #########################################

import atexit
import cv2
import numpy as np
import sys
import os
import matplotlib.pyplot as plt

from itertools import combinations

from .vcontours import vContour, vContours
from .config import __IDENT__, eprint
from .colors import BLACK, WHITE, RED, GREEN, BLUE, TEAL, PURPLE, YELLOW
from .colors import vColor


####################################################################################################
########################################### vImg CLASS #############################################


class vImg(np.ndarray):

    ####################################################################################################
    ########################################## DUNDER METHODS ##########################################

    def __new__(cls, imgFn=None, **kwargs) -> np.ndarray:
        """Initiates a vImg object using np.ndarray as base class. The vImg object extends the array
        to allow for image modification methods to be executed on the base class.
        Parameters:
            imgFn = string, path to image
            **kwargs (optional, only color may be used if img is supplied)
            img    : numpy np.ndarray type
            height : in pixels, height of the blank image
            width  : in pixels, width of the blank image
            color  : in RGB tuple, the bg color for the blank image (default: black)
            title  : string, set the title property for the image object (otherwise
                     this is generated by a sequence generator
        """

        def blank(height : int, width : int, clr=BLACK) -> np.ndarray:
            """Creates a blank image
            Parameters:
                height : int, pixel height of the blank image
                width  : int, pixel width of the blank image
                clr    : tuple, RGB tuple representing the background color for the blank image 
                         (default: black). Remember, in OpenCV rgb values are stored as (B,G,R)
            """
            blank_image = np.zeros((height, width, 3), dtype='uint8')
            clr = vColor(clr)
            if clr != BLACK: blank_image[:, :] = clr
            return blank_image

        if imgFn is None:
            try:
                if kwargs.get('img', None) is not None:
                    # if the img parameter is provided
                    img = kwargs['img']

                else:
                    # create a blank image using at least the height and width optional parameters
                    img = blank(kwargs['height'], kwargs['width'], kwargs.get('color', BLACK))

                obj = np.asarray(img).view(cls)
                obj.__kwargs = kwargs
                obj.__h, obj.__w = obj.shape[:2]
                obj.__center = (obj.w // 2, obj.h // 2)
                obj.__color = kwargs.get('color', BLACK)
                return obj

            except KeyError:
                str_err = "KeyError: If 'image' argument not provided, keyword arg(s) for "
                str_err += ('width and height ' if not kwargs.get('height', None) and
                                                   not kwargs.get('width', None)
                            else 'height ' if not kwargs.get('height', None)
                            else 'width ' if not kwargs.get('width', None)
                            else 'unknown property ')
                str_err += 'must be provided (color is optional).'
                eprint(str_err)
                return



        try:
            obj = np.asarray(cv2.imread(imgFn)).view(cls)
            obj.__imgFn = imgFn
            obj.__h, obj.__w = obj.shape[:2]
        except cv2.error:
            raise ValueError("OpenCV Error occurred.") from None
        except:
            raise ValueError("Unable to open file at {}. Check the file exists.".format(imgFn)) \
                  from None

        obj.__center = (obj.__w // 2, obj.__h // 2)
        obj.__color = kwargs.get('color', (0, 0, 0))
        obj.__title = kwargs.get('title', None)
        obj.__kwargs = kwargs
        obj.__kwargs['imgFn'] = f"'{imgFn}'"
        return obj

    def __array_finalize__(self, obj):
        if obj is None: return
        self.__h = getattr(obj, '__h', None)
        self.__w = getattr(obj, '__w', None)
        self.__center = getattr(obj, '__center', None)
        self.__color = getattr(obj, '__color', None)
        self.__title = getattr(obj, '__title', None)
        self.__imgFN = getattr(obj, '__imgFN', None)
        self.__kwargs = getattr(obj, '__kwargs', None)
        self.__cDict = {'b': 'Blue', 'g': 'Green', 'r': 'Red'}
        self.__current_title = self.__title

    def __array_wrap__(self, out_arr, context=None):
        """__array_wrap__ gets called at the end of numpy ufuncs and
        other numpy functions, to allow a subclass to set the type of
        the return value and update attributes and metadata"""
        out_arr.__h = self.__h
        out_arr.__w = self.__w
        out_arr.__center = self.__center
        out_arr.__color = self.__color
        out_arr.__title = self.__title
        out_arr.__imgFN = self.__imgFN
        out_arr.__kwargs = self.__kwargs
        out_arr.__cDict = {'b': 'Blue', 'g': 'Green', 'r': 'Red'}
        out_arr.__current_title = self.__title

        return np.ndarray.__array_wrap__(self, out_arr, context)

    def __eq__(self, other):
        return np.array_equal(self, other)

    def __copy__(self):
        return vImg(img=self)

    def __repr__(self):
        """ Repr reproduces the expression that created the image object as exactly as possible, a notable
        limitation is that when built using a local path, the object reproduces the local path used.
        May change this behavior in the future to just return the string representation of the image array,
        but this method is usually much more readable.
        """
        key_words = ', '.join(f'{k} = {i}' for k,i in self.__kwargs.items())

        return f'vImg({key_words})'


    ####################################################################################################
    ######################################### IMAGE PROPERTIES #########################################

    @property
    def h(self):
        if self.__h is None:
            self.__h = self.shape[0]
        return self.__h

    @h.setter
    def h(self, val):
        self.__h = val

    @property
    def w(self):
        if self.__w is None:
            self.__w = self.shape[1]
        return self.__w

    @w.setter
    def w(self, val):
        self.__w = val

    @property
    def height(self):
        return self.h

    @height.setter
    def height(self, val):
        self.h = val

    @property
    def width(self):
        return self.w

    @width.setter
    def width(self, val):
        self.w = val

    @property
    def center(self):
        if self.__center is None:
            self.h, self.w = self.shape[:2]
            self.__center = (self.w // 2, self.h // 2)
        return self.__center

    @property
    def color(self):
        return self.__color

    @color.setter
    def color(self, val):
        self.__color = val

    @property
    def title(self):
        if self.__title is None:
            self.title = 'img' + next(__IDENT__)
        return self.__title

    @title.setter
    def title(self, val):
        assert isinstance(val,str), 'Title must be of type string'
        self.__title = val

    ####################################################################################################
    ################################### GENERAL TRANSFORMATION TOOLS ###################################
    ###################### Reused very little of Dr. Adrian Rosebrock's code and #######################
    ########################### comments from his excellent package imutils ############################
    #########################  and book 'Practical Python and OpenCV' below.  ##########################

    def BGR2RGB(self):
        image = cv2.cvtColor(self.copy(), cv2.COLOR_BGR2RGB)
        return vImg(img=image)

    def RGB2BGR(self):
        image = cv2.cvtColor(self.copy(), cv2.COLOR_RGB2BGR)
        return vImg(img=image)

    def gray(self):
        """ function that returns a grayscale transformed from BGR version of the vImg object """
        gray = cv2.cvtColor(self.copy(), cv2.COLOR_BGR2GRAY)
        return vImg(img=gray)

    def BGR2HSV(self):
        image = cv2.cvtColor(self, cv2.COLOR_BGR2HSV)
        return vImg(img=image)

    def grayHSV(self):
        """ function that returns a grayscale transformed from HSV version of the vImg object """
        V = cv2.split(self.BGR2HSV())[2] # grab the third element (the value channel)
        return vImg(img=V)

    def translate(self, x : int, y : int):
        """ function that returns translated (shifted by x and y pixels) image
        x : int, number of pixels to move the image horizontally (positive right, negative left)
        y : int, number of pixels to move the image vertically (positive down, negative up)
        """
        # Define the translation matrix and perform the translation
        M = np.float32([[1, 0, x], [0, 1, y]])
        shifted = cv2.warpAffine(self, M, (self.shape[1], self.shape[0]))
        # Return the translated image
        return vImg(img=shifted)

    def rotate(self, angle = 90, center = None, scale = 1.0):

        if not center: center = self.center
        # Perform the rotation
        M = cv2.getRotationMatrix2D(center, angle, scale)
        rotated = cv2.warpAffine(self, M, (self.w, self.h))

        # Return the rotated image
        return vImg(img=rotated)

    def resize(self, width = None, height = None, interpolation = cv2.INTER_AREA):
        """ function that returns a resized image based on a given width, height, or both.
        Maintains the aspect ratio of the image if given only one dimension.
        width  : int, optional, width in pixels for the resized image
        height : int, optional, height in pixels for the resized image
        inter  : cv2 CONSTANT, optional, interpolation method
        Valid values for inter:
        cv2.INTER_AREA (default)
        cv2.INTER_NEAREST
        cv2.INTER_CUBIC
        cv2.INTER_LINEAR
        cv2.INTER_LANCZOS4
        """
        # initialize the dimensions of the image to be resized and grab the image size
        (h, w) = self.shape[:2]

        # if both the width and height are None, then return the original image
        if width is None and height is None:
            return vImg(img=self)

        # check to see if the width is None
        if width is None:
            # calculate the ratio of the height and construct the dimensions
            r = height / float(h)
            dim = (int(w * r), height)

        # otherwise, the height is None
        else:
            # calculate the ratio of the width and construct the dimensions
            r = width / float(w)
            dim = (width, int(h * r))

        # resize the image
        resized = cv2.resize(self.copy(), dim, interpolation=interpolation)

        # set the new state and img of the resized img
        return vImg(img=resized)

    ####################################################################################################
    ######################################## THRESHOLDING TOOLS ########################################

    def threshold(self, T, k = 5, inverse = True):
        """ We will apply binary thresholding from the current image object and return
        the second result i.e. the threshold map (extremely basic)
        T : int, threshold pixel intensity
        k : kernel size in square pixels for gaussian blur, default to 5
        inverse: bool, whether or not to return an inverse binary threashold, default YES
        """
        # The value of k must be odd so that there's a center pixel in the matrix
        if k % 2 == 0: raise ValueError(f'k must be an odd number... not {k}') from None

        # First, convert the color scale of the image to grayscale, then apply a gaussian blur
        image = cv2.cvtColor(self.copy(), cv2.COLOR_BGR2GRAY)
        gauss = cv2.GaussianBlur(image, (k,k), 0)

        # Next, apply the threshold to the image
        thresh_bin = cv2.THRESH_BINARY if inverse is not True else cv2.THRESH_BINARY_INV
        thresh = cv2.threshold(gauss, T, 255, thresh_bin)[1]

        # Finally, return the result
        return vImg(img=thresh)

    def adaptiveThreshold(self, adaptive_method = cv2.ADAPTIVE_THRESH_GAUSSIAN_C, neighborhood = 25,
                          k = 5, C = 0, inverse = True):
        """ We will apply adaptive thresholding to the image object and return a threshold map
        based off of a given neighborhood size.
        adaptive_method   : cv2 constant that represents which adaptive thresholding method we will
                            use (e.g. cv2.ADAPTIVE_THRESH_MEAN_C, cv2.ADAPTIVE_THRESH_GAUSSIAN_C)
        neighborhood      : int, default 25, size of the neighborhood in which to evaluate small areas 
                            of pixels in order to find an optimal value of T to apply thresholding
        k                 : int, kernel size in square pixels for gaussian blur, default to 5
        C                 : int, subtracted from the mean, giving us granular control of the adaptive
                            thresholding process, default to 0
        inverse           : bool, value representing whether or not the threshold constant used will
                            be inverse or normal. Inverse is default since it's commonly used for
                            masking.
        """
        # The value of k must be odd so that there's a center pixel in the matrix
        if k % 2 == 0: raise ValueError(f'k must be an odd number... not {k}')

        # First, assert the color of the image is grayscale, then apply a gaussian blur
        assert len(self.shape) == 2, "Must use on grayscale image"
        gauss = cv2.GaussianBlur(self, (k,k), 0)

        # determine whether to use standard or inverse binarization method
        thresh_bin = cv2.THRESH_BINARY if not inverse else cv2.THRESH_BINARY_INV

        # Next, apply the threshold to the image
        thresh = cv2.adaptiveThreshold(gauss, 255, adaptive_method, thresh_bin, neighborhood, C)

        # Return the new vImg object
        return vImg(img=thresh)

    ####################################################################################################
    ########################################## GRADIENT TOOLS ##########################################

    def Laplacian(self):
        """Performed on a grayscale image, returns the Laplacian gradient of the image.
        :return: 
        :rtype: vImg
        """
        lap = cv2.Laplacian(self, cv2.CV_64F)
        lap = np.uint8(np.absolute(lap))
        return vImg(img=lap)

    def sobelX(self):
        """Performed on a grayscale image, returns the Sobel gradient image along the X axis
        :return: 
        :rtype: vImg
        """
        # Calculate the Sobel gradient along the X-axis
        sobelX = cv2.Sobel(self, cv2.CV_64F, 1, 0)
        return vImg(img=sobelX)

    def sobelY(self):
        """Performed on a grayscale image, returns the Sobel gradient image along the Y axis
        :return: 
        :rtype: vImg
        """
        # Calculate the Sobel gradient along the Y-axis
        sobelY = cv2.Sobel(self, cv2.CV_64F, 0, 1)
        return vImg(img=sobelY)

    def sobelCombined(self):
        """Performed on a grayscale image, returns the Sobel gradient image along both axes.
        :return: 
        :rtype: vImg
        """

        # Calculate the Sobel gradient along the X-axis
        sobelX = cv2.Sobel(self, cv2.CV_64F, 1, 0)
        # Calculate the Sobel gradient along the Y-axis
        sobelY = cv2.Sobel(self, cv2.CV_64F, 0, 1)

        sobelBoth = cv2.bitwise_or(sobelX, sobelY)

        return vImg(img=sobelBoth)

    ####################################################################################################
    ######################################## EDGE MAPPING TOOLS ########################################

    def autoCanny(self, sigma=0.33):
        # compute the median of the single channel pixel intensities
        v = np.median(self)

        # apply automatic Canny edge detection using the computed median
        lower = int(max(0, (1.0 - sigma) * v))
        upper = int(min(255, (1.0 + sigma) * v))
        edged = cv2.Canny(self, lower, upper)

        # return the edged image
        return vImg(img=edged)

    ####################################################################################################
    ########################################## CONTOUR TOOLS ###########################################

    def simpleContours(self, quantity = cv2.RETR_EXTERNAL, complexity = cv2.CHAIN_APPROX_SIMPLE):
        """Performs simple cv2.findContours operation using common but overridable default 
           parameters on a vImg object, returns a list of vContour
        
        quantity    : cv2.RETR_EXTERNAL (default), also could be: cv2.RETR_LIST, cv2.RETR_COMP, 
                      and cv2.RETR_TREE
        complexity  : cv2.CHAIN_APPROX_SIMPLE (default), also could be: cv2.CHAIN_APPROX_NONE
        
        Passes the second element returned from cv2.findContours to the vContour class's fromList
        builder. Returns a vContours list of vContour objects. 
        
        Returns the 2nd element because the first element returned by cv2.findContours is 
        a 'destroyed' version of the image passed to it.
        """
        try:
            return vContour.fromList(cv2.findContours(self.copy(), quantity, complexity)[1])
        except cv2.error:
            eprint("\nOpenCV Error: likely tried to use image that has not been thresholded. \n"
                  "Now attempting to continue this operation using autoCanny(). \n"
                  "To avoid this error message, pass only edge maps to the simpleContours() function,\n"
                  "e.g. vImg('test.png').autoCanny().simpleContours()\n")
            return vContour.fromList(cv2.findContours(self.autoCanny(), quantity, complexity)[1])

    def evalContours(self, cnts = None, count = None, reverse = True,
                     outline_color = GREEN, font_color = WHITE):
        """This function exists to make it easier to evaluate contours in an image. Calling this
        function and supplying a list of contours iterates through the list of contours and
        identifies them one at a time on the image while simultaneously displaying useful
        simple and advanced contour properties in the console.
        
        Very useful for determining if contour analysis may be used effectively in a given 
        application. Not generally applicable or useful in a production environment.
        
        cnts          : vContours object (list of vContour), use the simpleContours method to 
                        easily generate a vContours object
        count         : int, if supplied, the contours will be sorted and count will determine 
                        how many are returned
        reversed      : bool, defaults to False, if set True when called, contours will be 
                        size-sorted in reverse (big to small) before being truncated to count 
                        number of contours.
        outline_color : tuple (3 unsigned 8-bit integers), 3-tuple indicating color of outline 
                        in RGB format
        font_color    : tuple (3 unsigned 8-bit integers), 3-tuple indicating color of label 
                        text in RGB format
        """

        if cnts is None:
            cnts = self.simpleContours()

        assert isinstance(cnts, vContours), 'Must be vContours iterable'

        if count is not None:
            cnts.sizeSort(reverse=reverse)
            cnts = cnts[:count]

        if not isinstance(outline_color, vColor):
            outline_color = vColor(outline_color)

        if not isinstance(font_color, vColor):
            font_color = vColor(font_color)

        img = self.copy()

        for i, c in enumerate(cnts, 1):
            cv2.drawContours(img, [c], -1, outline_color.BGR(), 1)
            cv2.putText(img, f'#{i}', (c.x, c.y - 5), cv2.FONT_HERSHEY_SIMPLEX,
                        0.5, font_color.BGR(), 2)
            print(f"""Shape #{i} @ x({c.x},{c.x2}) y({c.y}, {c.y2})
            --------------------------------------------------------------
            width: {c.width} height: {c.height}
            Aspect Ratio is (image width / image height): {c.aspect_ratio:.2f}
            Contour Area is: {c.area:.2f}
            Bounding Box Area is: {c.w * c.h:.2f}
            Convex Hull Area is: {c.hull_area:.2f}
            Solidity (Contour Area / Convex Hull Area) is: {c.solidity:.2f} 
            Extent (Contour Area / Bounding Box Area) is: {c.extent:.2f}
            Center is located at: {c.center}""")
            cv2.imshow(self.title, img)
            cv2.waitKey(0)
        atexit.register(cv2.destroyAllWindows)

    ####################################################################################################
    ######################################### HISTOGRAM TOOLS ##########################################

    def histFlat(self, RGB = (True,)*3, mask = None, bins = (256,), xlimit = (0, 256),
                 normal = True, display = True):
        """ By adding a single 3-tuple bool parameter (RGB) to indicate which channels are active 
        in the histogram, we can make showing different types of histograms trivial.
        """

        if not isinstance(bins, list):
            bins = list(bins)

        if not isinstance(xlimit, list):
            xlimit = list(xlimit)

        # TODO: Make sure changing bins and xlimit to tuple doesn't have ill effects on function call

        results = {}
        # Check if image is grayscale
        assert RGB != (False, False, False), "To get a grayscale histogram from a color image, " \
                                             "first convert to grayscale using the gray() method"

        if len(self.shape) == 2: # 1-dimensional grayscale image
            if display:
                plt.figure()
                plt.title(f"'Flattened' Grayscale Histogram ('{self.title}')")
                plt.xlabel("Bins")
                plt.ylabel("# of Pixels")

            hist = cv2.calcHist([self], [0], mask, bins, xlimit)

            if normal:
                hist /= hist.sum()

            if display:
                plt.plot(hist, color='k')
                plt.xlim(xlimit)

            results.update({'k' : hist})

        elif len(self.shape) == 3: # 2-dimensional image with at least 1 color channel

            channels = cv2.split(self)
            colors = ('b', 'g', 'r')
            cczip = tuple(e for e in zip(channels, colors, RGB[::-1]) if e[2] is True)

            if display:
                plt.figure()

            *chans, final_chan = [self.__cDict[e[1]] for e in cczip]

            if display:
                plt.title('Flattened Color Histogram for color channels '
                          f"{' '.join(e for e in chans)}, and {final_chan} ('"
                          f"{self.title}').")
                plt.xlabel("Bins")

                if normal:
                    plt.ylabel("Percentage of total")
                else:
                    plt.ylabel("# of Pixels")

            for chan, clr, _ in cczip:
                hist = cv2.calcHist([chan], [0], mask, bins, xlimit)

                if normal:
                    hist /= hist.sum()

                if display:
                    plt.plot(hist, color=clr)
                    # plt.xlim(xlimit) already specified

                results.update({ clr : chan })

        return results

    def hist2D(self, RGB = (True,)*3, mask = None, bins = (32, 32),
               xlimit = (0, 256, 0, 256), display = True):
        """ Function for creation/viewing a two-dimensional histogram
        
        """
        #TODO: Make sure changing bins and xlimit to tuple doesn't have ill effects on function call

        if not isinstance(bins, list):
            bins = list(bins)

        if not isinstance(xlimit, list):
            xlimit = list(xlimit)
        assert len(self.shape) > 2, "Two dimensional histograms must not be grayscale"

        horizontal_subchannels = len([e for e in RGB if e is True])


        if horizontal_subchannels == 3:
            fig, axs = plt.subplots(1, 3) # sharey = False, sharex = False
        else:
            fig = plt.figure()

        i = 0

        colors = ('B', 'G', 'R')
        # split the channels of the image into the RGB components
        channels = cv2.split(self)
        # create a list that contains each color that needs to be tested, a string representation
        # of that color, and a bool representing whether that color is included, filter out False
        # (colors,
        cczip = (e for e in zip(channels, colors, RGB[::-1]) if e[2] is True)
        # Create generator for all unique combinations of colors that are included

        channels = combinations(((chan, color) for chan, color, _ in cczip), 2)

        print(f'{"itertools.combinations" in sys.modules}')
        print(f'{"itertools" in sys.modules}')
        results = {}
        for (chan1, color1), (chan2, color2) in channels:
            hist = cv2.calcHist([chan1, chan2], [0, 1], mask, bins, xlimit)
            if horizontal_subchannels == 3 and display:
                # subplot_num = 100 + 10 * horizontal_subchannels + i
                # ax = fig.add_subplot(subplot_num)
                axs[i].set_title(f"2D Color Histogram for {color1} and {color2}")
                p = axs[i].imshow(hist, interpolation="nearest")
                fig.colorbar(p, ax=axs[i])
                i += 1

            elif display:
                plt.title(f"2D Color Histogram for {color1} and {color2}")
                plt.xlim(xlimit)
                p = plt.imshow(hist, interpolation="nearest")
                plt.colorbar(p)

            results.update({ (color1, color2) : hist })

        return results

    def hist3D(self, mask = None, bins = (8, 8, 8), xlimit = (0, 256, 0, 256, 0, 256), display = True):
        """ Function that returns a three dimensional histogram based on the current image object using 
        the OpenCV calcHist function. 
        :param mask    :
        :param bins    :
        :param xlimit  :
        :param display : 
        
        """

        # TODO: Make sure changing bins and xlimit to tuple doesn't have ill effects on function call

        if not isinstance(bins, list):
            bins = list(bins)

        if not isinstance(xlimit, list):
            xlimit = list(xlimit)

        hist = cv2.calcHist([self], [0, 1, 2], mask, bins, xlimit)

        if display:
            print(f"3D histogram shape: {hist.shape}, with {hist.flatten().shape[0]} values")

        return hist

    def equalizeHist(self, error_on_color = False):

        if len(self.shape) == 2:
            return vImg(img=cv2.equalizeHist(self))
        else:
            if error_on_color:
                raise ValueError("Histogram equalization requires histogram to be grayscale")
            else:
                return vImg(img=cv2.equalizeHist(self.gray()))

    ####################################################################################################
    ###################################### OBJECT DETECTION TOOLS ######################################

    def mask(self):
        """ Return a blank mask the size of the original image."""
        return np.zeros(self.shape, dtype="uint8")

    def connectedComponents(self, connectivity = 8, type = cv2.CV_32S):
        """ Perform connected component analysis and return a matrix of labels corresponding
        to the found objects in the analyzed image. 0 represents background, while integers 
        above zero correspond to the label of a single found object.
                
        :param connectivity : int, 8 or 4 for 8-way or 4-way connectivity, respectively
        :param type         : Currently CV_32S and CV_16U are supported.
        :return             : mat of labels corresponding to the found components
        """

        return cv2.connectedComponents(self, connectivity, type)[1] # only return the label matrix


    def pyramid(self, scale=1.5, min_size=(64, 64)):
        """ Generator that returns successively smaller versions of an image object until a supplied
        minimum size is reached.
        :param scale   : float, The denominator by which the width of the image is successively divided.
        :param min_size : 2-tuple of integers, (minY, minX), minimum dimensions for the image, if the 
                         image is made smaller than these supplied dimensions the generator ends.
        :return        : yields successively smaller images until a minimum is reached, based on the 
                         supplied parameters.
        """
        # yield the original self
        yield self

        # need the following line to make sure self doesn't refer to the original object's state,
        # which results in an infinite loop
        image = self

        # separate the values from min_size for clarity
        minX, minY = min_size

        # keep looping over the pyramid
        while True:
            # compute the new dimensions of the self and resize it
            w = int(image.w / scale)

            # the following line always resizes from the original object (self) to avoid a
            # recursive reduction in quality. w always gets smaller so image also gets
            # successively reduced in size.
            image = self.resize(width=w)

            # if the resized image becomes smaller than the supplied minimum allowed
            # size, then stop constructing the pyramid
            if image.h < minY or image.w < minX:
                return

            # yield the next image in the pyramid
            yield image

    def slidingWindow(self, step_size = 32, window_size = (64, 64)):
        # slide a window across the image, yielding the current window

        yield from ((x, y, self[y:y + window_size[1], x:x + window_size[0]])
                    for y in range(0, self.height, step_size)
                    for x in range(0, self.width, step_size))

    def windowPyramidChain(self, scale = 1.5, min_size = (64, 64), step_size = 32,
                                  window_size = (64, 64)):
        """
        
        :param scale       : 
        :param min_size    : 
        :param step_size   : 
        :param window_size : 
        :return            : 
        """

        yield from ((x, y, window, layer) for layer in self.pyramid(scale, min_size)
                    for x, y, window in layer.slidingWindow(step_size, window_size))




    ####################################################################################################
    ####################################### IMAGE DISPLAY TOOLS ########################################

    def show(self, title = None, wait = 0, waitKey = True, destroy = True):
        """ Display the image using opencv's imshow functions. Also optionally follows that command
        up with the waitKey function with an optionally provided wait time. Always registers the
        cv2.destroyAllWindows function to run at program exit to ensure cleanup.
        
        :param title   : Optional, string, represents an optionally provided custom title for the window 
                         in which the image is displayed. If this is not provided, the image's title
                         property is used for the window instead. Does not set the title.
        :param wait    : Optional, int (default is 0), represents the number of seconds provided to the 
                         cv2.waitKey function.
        :param waitKey : Optional, bool (default is True), set this parameter to False to disable invoking
                         the cv2.waitKey function.
        :param destroy : Optional, bool (default is True), set this parameter to False to disable registering
                         cv2.destroyAllWindows at exit.
        """
        # TODO: Any negative effects from using atexit functionality to always run destroyAllWindows?

        if title is None:
            title = self.title

        self.__current_title = title

        cv2.imshow(title, self)

        if waitKey:
            cv2.waitKey(wait)

        if destroy:
            atexit.register(cv2.destroyAllWindows)

    def hide(self):
        """ Attempt to kill a currently open image """
        try:
            cv2.destroyWindow(self.__current_title)

        except cv2.error:
            eprint('\n[+] OpenCv Error prevented closing of requested window.\n')


